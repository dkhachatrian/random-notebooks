{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some math shtuff\n",
    "\n",
    "A quick reference for some concepts whose intuitions/simple methods of understanding sometimes escape me.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy, Cross-Entropy, KL Divergence\n",
    "\n",
    "There are a number of ways to think about/get to the Shannon entropy ($H$) (thankfully not $S$...) One simple way is to say what we want it to mean qualitatively and impose some desired characteristics to determine its mathematical formulation. In this case, it may make more sense to start with cross-entropy first.\n",
    "\n",
    "Say you're sending me messages from an alphabet of symbols $A$. Some are more likely than others, and we'll call the probability distribution associated with the actual generator of symbols $p$. I'm over here on the other side thinking like I'm a pair of smartypants ~~and start looking to spread my brand through nationwide department stores~~ that has figured out how likely you are to send each symbol to me. We'll call my expected distribution (which may or may not be the correct distribution) $q$.\n",
    "\n",
    "Now we want to measure how surprised I am by any given message you send me -- let's call it $\\tau$ (rhymes with \"wow\" -- alas, $\\tau$ is not standard notation). We would imagine the following properties would be useful for $\\tau$ to have:\n",
    "1. The more surprised I am, the larger $\\tau$ gets (otherwise, it wouldn't exactly be doing a good job measuring my surprise)\n",
    "2. If symbols are independently generated, we can construct the total surprise of my message by adding the total surprise of each symbol in the message, i.e., $\\tau_{M} = \\sum_{i=1}^{m} \\tau_{M[i]}$ where $M \\in A^m$ is a string of symbols, $m$ is the cardinality of $M$, and $M[i]$ denotes the $i$'th element of $M$.\n",
    "\n",
    "Using these two criteria, a reasonable mapping is\n",
    "\n",
    "$$\\tau_{a} = \\log\\left(\\frac{1}{q_a}\\right), a \\in A$$\n",
    "\n",
    "where $q_a$ is the probability I think you'll send the symbol $a$.\n",
    "\n",
    "I mean, that's great and all, but that works for individual instances of strings or symbols. How much should I *expect* to be surprised by any given symbol? Well, that'd depend on how often you *actually* send me a symbol, alongside how often I expect to receive that particular symbol.\n",
    "\n",
    "Hmm, this smells of expectation! And indeed, that's all we do -- take the expectation over A (using the *actual* probability of each symbol occurring, i.e., using $p$) of my surprise per symbol:\n",
    "\n",
    "$$E_{a \\sim p}[\\tau] = \\sum_{a \\in A} p_a \\log\\left(\\frac{1}{q_a}\\right) = H(p,q)$$\n",
    "\n",
    "We denote this metric $H(p,q)$ (where $p$ and $q$ are the actual and presumed distributions, respectively) and call it the **cross-entropy** (because that sounds pretty cyberpunk to me. I like to think they throw in \"cross\" because it measures the surprise caused by \"crossing\" the distributions $p$ and $q$ together.)\n",
    "\n",
    "Now, we'd imagine that I'd be the least surprised if my presumed distribution of symbols were in fact the actual distribution, i.e. when $p = q$. In fact, this is true!\n",
    "\n",
    "$$H(p,p) = H(p) = \\sum_{a \\in A} p_a \\log\\left(\\frac{1}{p_a}\\right)$$\n",
    "\n",
    "is called the **entropy** (or **Shannon entropy**) of the probability distribution and written $H$ (thankfully not $S$...). Usually, the $log$s written above are base-2. This permits a way of thinking of the value of the Shannon entropy: if I'm only allowed to ask the same series of questions to you to figure out which symbol you want to send me and I know the actual probability distribution $p$ of symbols, how many questions should I expect to ask (i.e. mean/average) before I figure out the answer? The cross-entropy is the same thing, expect I don't necessarily know the actual probability distribution $p$ of symbols, I just think I do (and I think it's $q$) and base my series of questions based on $q$.\n",
    "\n",
    "Now, hopefully that makes it clear that $ p \\neq q \\implies H(p,q) > H(p) $ -- if I don't know the actual distribution, I'm not going to be able to answer the most optimal series of questions. This suggestions to us a notion of \"distance\" (i.e. a metric) between the probability distributions $p$ and $q$:\n",
    "\n",
    "$$ KL(p \\mid\\mid q) = H(p,q) - H(p) $$\n",
    "\n",
    "This metric is called the **Kullbackâ€“Leibler divergence** (because names) or the **KL divergence** (because initialisms), or seemingly most rarely but probably most clearly the **relative entropy**. It's be of \"the \\[blah\\] of p with respect to q\". The closer the KL divergence is to 0, the closer $q$ is to being $p$, and $ KL(p \\mid\\mid q) = 0 \\implies p = q $ at every point in the domain of $q$ (which is the same as the domain of $p$).\n",
    "\n",
    "This makes describing the **mutual information** of random variables X and Y in terms of a KL divergence fairly intuitive. Just running off the name, if X and Y were independent, you'd expect no mutual information between them. In such a case, $P(X,Y) = P(X)P(Y)$, and $ KL\\left(P(X,Y)\\mid\\mid P(X)P(Y)\\right) = 0$. And in fact, one way of writing the mutual information of random variables X and Y is exactly\n",
    "\n",
    "$$ I(X;Y) = KL\\left(P(X,Y)\\mid\\mid P(X)P(Y)\\right) $$\n",
    "\n",
    "which I think is pretty neat.\n",
    "\n",
    "\\- DK (4/24/18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes' Theorem\n",
    "\n",
    "I can never seem to remember Bayes' Theorem directly, as they write it out in textbooks. It makes so much more sense to me to think about it from the relationships between conditional and joint probabilites/distributions, and one of the common tricks to make Bayes' Theorem useful in practice also comes to me far more easily when explicitly thinking about events as being sampled from a *sample space* of possibilities/outcomes.\n",
    "\n",
    "\n",
    "\n",
    "Consider two possible events A and B. Let's keep in mind that A is just one possible outcome out of a set of possibilities, as is B; we'll say $\\alpha$ is the set of possibilities from which $A$ was drawn and $\\beta$ is the set of possibilities from which $B$ was drawn, i.e. $A \\sim \\alpha$ and $B \\sim \\beta$ (this will be good to remember later). Now:\n",
    "\n",
    "$$ \\text{Pr[A and B both occur]} := P(A,B) $$\n",
    "\n",
    "Assuming individual events happen separately, there are two ways for both A and B to occur:\n",
    "1. A happens first, then B happens.\n",
    "2. B happens first, then A happens.\n",
    "\n",
    "(\"Duh\", I know.)\n",
    "\n",
    "Keeping in mind that the first event might affect the probability of the second event occurring (i.e. remembering that conditional probabilities exist), we can write:\n",
    "\n",
    "$$ P(A,B) = P(A) \\times P(B \\mid A) = P(B) \\times P(A \\mid B) $$\n",
    "\n",
    "And then it's simple to write out Bayes' Theorem as it's often written (we'll write it perhaps a bit more evocatively):\n",
    "\n",
    "$$ P(B) \\times P(A \\mid B) = P(A) \\times P(B \\mid A) $$\n",
    "\n",
    "$$\\begin{align} P(A \\mid B) &= \\frac{P(A) \\times P(B \\mid A)} {P(B)} \\\\\n",
    "                        &= P(A) \\times \\frac {P(B \\mid A)} {P(B)} \\end{align}$$\n",
    "\n",
    "Using the Bayesian interpretation: At first we thought the probability that $A$ occurs is $P(A)$. After we saw that $B$ happened, we re-evaluate the probability that $A$ occurs with a scaling factor $ \\frac {P(B \\mid A)} {P(B)} $\n",
    "\n",
    "Also worth knowing the fancy terminology:\n",
    "- the **_a priori_ probability** or just the **prior** is what we thought would be the probability that a random variable takes on a certain value before we observed anything. So the *a priori* probability (or just prior) for the event $A$ would be $P(A)$. If we consider $A$ to be a random variable instead of an event, we're guessing the distribution of $A$ and so $P(A)$ would be an **_a priori_ distribution** (or again, just the prior).\n",
    "- the **_a posteriori_ probability** or just the **posterior** is what we think the probability that a random variable takes on a certain value is after observing something. In this case, the *a posteriori* probability (or just posterior) of the event $A$ after observing $B$ is $P(A \\mid B)$. If we consider $A$ to be a random variable instead of an event, we're guessing the distribution of $A$ after observing a random variable/event B and so $P(A \\mid B)$ would be an **_a posteriori_ distribution**, (or again, just the posterior).\n",
    "\n",
    "\n",
    "Now, in cases of inference, we normally have some data on the likelihood of one of the conditionals -- let's say $P(B \\mid A)$ to avoid flipping our equation around again -- via empirical counts. So we've already guessed some prior $P(A)$, and we're trying to improve it by calculating the posterior $ P(A \\mid B) $. But what if we don't know $ P(B) $? Is our guessing and data collection all for naught!? Thankfully, not so! The answer lies right under our noses -- or in this case, in our previous calculations.\n",
    "\n",
    "Consider $P(A,B)$ again. What would we get if we added $P(A,B)$ over all possible values of A? (Remember we said that $A \\sim \\alpha$, so A could have been some other event within the set $\\alpha$.) That's basically just saying that we don't care what value $A$ is, so we end up with $P(B)$! ('!' used to denote excitement, not factorialization.) And conveniently, we'd already have a way to estimate these values:\n",
    "\n",
    "$$\\begin{align} P(B) &= \\sum_{A \\in \\alpha} P(A,B) \\\\\n",
    "                     &= \\sum_{A \\in \\alpha} P(A) \\times P(B \\mid A)          \\end{align}$$\n",
    "\n",
    "Our summand is the same as the values we've estimated either by guessing ($P(A)$) or from our data ($P(B \\mid A)$)! With that, we can rewrite our earlier equation as \n",
    "\n",
    "$$ P(A \\mid B) = \\frac{P(A) \\times P(B \\mid A)} {\\sum_{A \\in \\alpha} P(A) \\times P(B \\mid A)} $$\n",
    "\n",
    "With that, we can crunch the numbers and perform Bayesian inference like a champ or have a machine do it for us like a prudent delegator. Though for our everyday activities, we often don't have the luxury of having someone/something checking our heuristics. So it's always worth trying to keep in mind that oftentimes, many different factors that you may not know or take into consideration can culminate in observations that surprise you -- there's a good reason you aren't told to constantly get yourself tested for a medical condition if you don't believe to be at risk!\n",
    "\n",
    "\\- DK (4/24/18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drafts and WIPs\n",
    "\n",
    "(Avert your eyes!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "## Bayes' Theorem\n",
    "\n",
    "I can never seem to remember Bayes' Theorem directly, as they write it out in textbooks. It makes so much more sense to me to think about it from the relationships between conditional and joint probabilites/distributions, and one of the common tricks to make Bayes' Theorem useful in practice also comes to me far more easily when explicitly thinking about events as being sampled from a *sample space* of possibilities/outcomes. (I find that when I read \"consider two possible events A and B\", I tend to forget that A can be one of several different events, so hopefully the discussion below is clearer in that regard.)\n",
    "\n",
    "// (like how sampling a \"number\" from a samples from a distribution instead of events (which is sampled from an event space, but like, who immediately thinks about events as having been sampled from an \"event space\"? (Statisticians I'd wager, but probably not too many other people.)).\n",
    "\n",
    "So, let's talk about the weather. (Sorry if the topic is a bit dry by this point.)\n",
    "\n",
    "Specifically, let's consider a forecast as described by two variables: type of coverage (\"sunny\", \"cloudy\", \"thunderstorms\", ...), which we'll call $C$, and average temperature for the day (in, say, degrees Fahrenheit and rounded to the nearest integer), which we'll call $T$. These are certainly random variables -- one has certainly cursed their weather app for faulty information when caught out in the rain without an umbrella. But they also definitely have some connection with one another -- you'd probably be surprised to find it snowing if you look up and it's a clear sunny day (if not, you'll have to tell me where such an odd sight takes place).\n",
    "\n",
    "We can consider the **sample space** of weather outcomes $W$, i.e. the space that contains all possible weather combinations, as being composed of two \"axes\", one being the set of all types of coverage (let's call that $C$) and the other being the set of all temperatures readings (let's call that $T$). So we can *kind of* think of things as:\n",
    "\n",
    "$$ W = C \\times T $$\n",
    "\n",
    "with $C \\times T$ being the Cartesian product of $C$ and $T$. I put all these (written) verbal asterisks because I'm stretching some definitions and not being super thorough: \"axes\" imply ordering, which doesn't always make sense (what comes after \"cloudy\" on the $C$ axis?) and isn't necessary; and the elements of $W$ needn't be tuples, unlike what a Cartesian product implies (and I'm also not sure whether one can actually apply the Cartesian product to random variables).\n",
    "\n",
    "All that said, each point $w \\in W$ describes a particular weather condition and has an associated probability. If we consider a particular weather condition with $w = (c,t), c \\in C, t \\in T$, we can write:\n",
    "\n",
    "$$ \\text{Pr[W = w]} = \\text{Pr[C = c and T = t]} $$\n",
    "\n",
    "Here we're following the convention that $\\text{Pr[X = x]}$ is the probability that the random variable $X$ takes on the value $x$. We'll also follow the convention where $\\text{Pr[X = x]} = P(x)$. So we'll write the above as:\n",
    "\n",
    "$$ P(w) = P(c,t) $$\n",
    "\n",
    "Now, being high-tech cosmologists, we have a way of sending a probe into the future and getting back information on either the sky coverage or the temperature. )\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
